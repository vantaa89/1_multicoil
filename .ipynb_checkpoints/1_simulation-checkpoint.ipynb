{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime   \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from scipy import io, signal\n",
    "import math\n",
    "import random\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import import_ipynb\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.data_simulation import MotionParameters, SimulatedDataset\n",
    "\n",
    "image_path = \"./Data/Uncombined_data1/\"\n",
    "sens_path = \"./Data/sensitivity1/\"\n",
    "init_rot = 10 \n",
    "motion_ran_lb = [0,0,0] #(offset, x-dif, y-dif)\n",
    "motion_ran_ub = [0.5,0.5,0.5]\n",
    "motion_PE_ran = [56, 224-56]\n",
    "SNR_ran = [100,200]\n",
    "img_size = [224, 224]\n",
    "# batch_size = 100 -> unused\n",
    "epochs = 50\n",
    "\n",
    "params = MotionParameters(img_size, SNR_ran, motion_ran_lb, motion_ran_ub, motion_PE_ran, rot=init_rot)\n",
    "train_ds = SimulatedDataset(image_path, sens_path, params, split='train', multiple=epochs)\n",
    "test_ds = SimulatedDataset(image_path, sens_path, params, split='test', multiple=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "complex128\n"
     ]
    }
   ],
   "source": [
    "corrupted, PE = train_ds[24]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "layer = 0\n",
    "for axes_x in axes:\n",
    "    for axis in axes_x:\n",
    "        axis.imshow(abs(np.fft.ifftn(corrupted[:,:,layer], axes=(0,1))), cmap=\"gray\")\n",
    "        # axis.imshow(abs(np.fft.fftshift(corrupted[:,:,layer])), cmap=\"gray\", vmin=0, vmax=1e-3)\n",
    "        axis.set_title(f\"layer: {layer + 1}, PE: {PE[layer]}\")\n",
    "        layer = layer + 1\n",
    "    \n",
    "print(len(train_ds))\n",
    "print(corrupted.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████▉                        | 157/450 [3:31:32<6:32:21, 80.35s/it]"
     ]
    }
   ],
   "source": [
    "save_path = \"./Data/h5/train2\"\n",
    "epoch_size = len(train_ds) // epochs\n",
    "data_cnt = 0\n",
    "start_epoch = 50\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for epoch in tqdm(range(start_epoch, epochs)):\n",
    "    # clear_output()\n",
    "    # print(f\"Epoch {epoch + 1} / {epochs}...\")\n",
    "    h5file_path = save_path + \"/\" + str(epoch) + \".h5\"\n",
    "    with h5py.File(h5file_path, \"w\") as f: # each epoch\n",
    "        group_no = 0\n",
    "        for data_no in range(epoch_size):  # number of the data in each epoch\n",
    "            brain, label = train_ds[data_no] # multi-layer, motion-corrupted dicom in k-space. (224, 224, 16)\n",
    "            for layer in range(brain.shape[-1]):\n",
    "                group = f.create_group(str(group_no))\n",
    "                group.create_dataset(\"image\", data=brain[:,:,layer], dtype=np.complex128)\n",
    "                group.create_dataset(\"label\", data=label[layer], dtype=int)\n",
    "                group_no = group_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:26<00:00,  8.69s/it]\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./Data/h5/test2\"\n",
    "epoch_size = len(test_ds)\n",
    "data_cnt = 0\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for epoch in range(0, 1):\n",
    "    h5file_path = save_path + \"/\" + str(epoch) + \".h5\"\n",
    "    with h5py.File(h5file_path, \"w\") as f:\n",
    "        group_no = 0\n",
    "        for data_no in tqdm(range(epoch_size)):  # number of the data in each epoch\n",
    "            brain, label = test_ds[data_no] # multi-layer, motion-corrupted dicom in k-space. (224, 224, 16)\n",
    "            for layer in range(brain.shape[-1]):\n",
    "                group = f.create_group(str(group_no))\n",
    "                group.create_dataset(\"image\", data=brain[:,:,layer], dtype=np.complex128)\n",
    "                group.create_dataset(\"label\", data=label[layer], dtype=int)\n",
    "                group_no = group_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motion",
   "language": "python",
   "name": "motion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
